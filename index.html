<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Personal Safety Assistant + Face & Voice</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
body{margin:0;font-family:Arial;background:#020617;color:#fff}
header{padding:15px;text-align:center;font-size:18px;border-bottom:1px solid #1e293b}
.container{padding:15px}
button,input,textarea{width:100%;padding:12px;margin-top:8px;border-radius:8px;border:none;font-size:15px}
button{background:#22c55e;color:#000;font-weight:bold}
.card{border:1px solid #1e293b;border-radius:10px;padding:12px;margin-top:12px}
.log{background:#000;padding:10px;border-radius:6px;min-height:60px;overflow-wrap: break-word;}
video,canvas{width:100%;border-radius:10px;margin-top:10px;}
#overlay{position:absolute;top:0;left:0;}
</style>
</head>
<body>

<header>ğŸ™ Personal Safety + Face & Voice Assistant</header>

<div class="container">

<button id="startBtn">â–¶ Start Assistant</button>

<div class="card">
<b>Heard</b>
<div id="heard" class="log">Waitingâ€¦</div>
</div>

<div class="card">
<b>Response</b>
<div id="response" class="log">---</div>
</div>

<div class="card">
<b>ğŸ“ Location</b>
<div id="loc" class="log">Inactive</div>
</div>

<div class="card">
<b>ğŸ¥ Camera Feed</b>
<video id="cam" autoplay playsinline muted></video>
<canvas id="overlay"></canvas>
</div>

<div class="card">
<b>ğŸ“ Test Form</b>
<input id="name" placeholder="Name">
<input id="note" placeholder="Note">
<button id="submitBtn" onclick="alert('Form Submitted!')">Submit</button>
</div>

</div>

<!-- Face API library -->
<script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

<script>
/* ==== GLOBAL VARIABLES ==== */
let rec, isVoiceActive=false;
let dictation=false, camStream=null, watchId=null;
const startBtn=document.getElementById("startBtn");
const heard=document.getElementById("heard");
const response=document.getElementById("response");
const loc=document.getElementById("loc");
const cam=document.getElementById("cam");
const overlay=document.getElementById("overlay");
const submitBtn=document.getElementById("submitBtn");
const nameInput=document.getElementById("name");
const noteInput=document.getElementById("note");

/* ==== SPEECH FUNCTIONS ==== */
function speak(text){
  speechSynthesis.cancel();
  let msg=new SpeechSynthesisUtterance(text);
  msg.rate=1; msg.pitch=1; msg.lang=navigator.language||"en-US";
  speechSynthesis.speak(msg);
  response.innerText=text;
}

/* ==== CAMERA ==== */
async function openCamera(){
  if(camStream) return;
  try{
    camStream = await navigator.mediaDevices.getUserMedia({video:{facingMode:"user"}, audio:false});
    cam.srcObject = camStream;
    cam.style.display="block";
    overlay.width=cam.videoWidth;
    overlay.height=cam.videoHeight;
    speak("Camera on");
    detectFaceLoop();
  }catch(err){speak("Camera permission denied or error");}
}
function closeCamera(){
  if(!camStream) return;
  camStream.getTracks().forEach(t=>t.stop());
  camStream=null;
  cam.style.display="none";
  speak("Camera off");
}

/* ==== LOCATION ==== */
function startTracking(){
  if(watchId) return;
  if(!navigator.geolocation){speak("Geolocation not supported"); return;}
  watchId=navigator.geolocation.watchPosition(pos=>{
    loc.innerHTML=`Lat: ${pos.coords.latitude}<br>Lng: ${pos.coords.longitude}<br>Accuracy: ${pos.coords.accuracy} m`;
  },err=>{speak("Location permission denied or error");},{enableHighAccuracy:true});
  speak("Location tracking started");
}
function stopTracking(){
  navigator.geolocation.clearWatch(watchId);
  watchId=null;
  loc.innerText="Location tracking stopped";
  speak("Tracking stopped");
}

/* ==== DICTATION ==== */
function typeCommand(cmd){
  if(dictation){
    let f=document.activeElement;
    if(f && (f.tagName==="INPUT"||f.tagName==="TEXTAREA")){
      f.value += cmd+" ";
    }
  }
}

/* ==== COMMAND HANDLER ==== */
function handle(cmd){
  heard.innerText=cmd;
  typeCommand(cmd);

  // Click buttons
  if(cmd.startsWith("click")){
    let text=cmd.replace("click","").trim();
    document.querySelectorAll("button").forEach(b=>{
      if(b.innerText.toLowerCase().includes(text)){
        b.click(); speak(text+" clicked");
      }
    });
    return;
  }

  // Emergency
  if(cmd.includes("emergency") || cmd.includes("help me")){
    speak("Emergency detected. Stay calm. Activate safety protocols.");
    return;
  }

  // Map of other commands
  const commands={
    "start camera": openCamera,
    "stop camera": closeCamera,
    "start tracking": startTracking,
    "stop tracking": stopTracking,
    "dictation on": ()=>{dictation=true;speak("Dictation on")},
    "dictation off": ()=>{dictation=false;speak("Dictation off")},
    "submit": ()=>submitBtn.click(),
    "clear form": ()=>{nameInput.value="";noteInput.value="";speak("Form cleared")},
    "status": ()=>speak("System running normally"),
    "what time": ()=>speak("The time is "+new Date().toLocaleTimeString()),
    "what date": ()=>speak("Today is "+new Date().toDateString()),
    "help": ()=>speak("Say start camera, start tracking, dictation on, or emergency")
  };
  for(let k in commands){if(cmd.includes(k)){commands[k](); return;}}
  speak("Command unclear");
}

/* ==== VOICE RECOGNITION ==== */
function startVoiceRecognition(){
  if(isVoiceActive) return;
  rec=new (window.SpeechRecognition||window.webkitSpeechRecognition)();
  rec.continuous=true;
  rec.interimResults=false;
  rec.lang=navigator.language||"en-US";
  rec.onresult=e=>{
    let cmd=e.results[e.results.length-1][0].transcript.toLowerCase().trim();
    handle(cmd);
  };
  rec.onerror=e=>{speak("Voice recognition error")};
  rec.start();
  isVoiceActive=true;
  speak("Voice Assistant activated. You can control everything now.");
}

/* ==== FACE RECOGNITION ==== */
let labeledDescriptors=null;
async function loadFaceModels(){
  await faceapi.nets.tinyFaceDetector.loadFromUri("https://justadomain.github.io/models");
  await faceapi.nets.faceLandmark68Net.loadFromUri("https://justadomain.github.io/models");
  await faceapi.nets.faceRecognitionNet.loadFromUri("https://justadomain.github.io/models");
  await faceapi.nets.ssdMobilenetv1.loadFromUri("https://justadomain.github.io/models");
  speak("Face models loaded");
}
async function detectFaceLoop(){
  if(!camStream) return;
  const displaySize={width:cam.videoWidth,height:cam.videoHeight};
  faceapi.matchDimensions(overlay, displaySize);
  setInterval(async ()=>{
    const detections=await faceapi.detectAllFaces(cam,new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks().withFaceDescriptors();
    const ctx=overlay.getContext("2d");
    ctx.clearRect(0,0,overlay.width,overlay.height);
    if(detections.length>0){
      const resizedDetections=faceapi.resizeResults(detections,displaySize);
      faceapi.draw.drawDetections(overlay,resizedDetections);
      faceapi.draw.drawFaceLandmarks(overlay,resizedDetections);
      // Optional: match with labeled descriptors if registered
    }
  },200);
}

/* ==== START BUTTON ==== */
startBtn.addEventListener("click",async ()=>{
  try{await navigator.mediaDevices.getUserMedia({audio:true,video:true});}catch(e){speak("Microphone/Camera permission denied"); return;}
  startVoiceRecognition();
  await loadFaceModels();
  openCamera();
});
</script>

</body>
</html>
